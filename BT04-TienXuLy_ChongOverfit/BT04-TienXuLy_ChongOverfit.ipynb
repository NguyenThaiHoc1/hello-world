{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT04: Tiền xử lý và chống overfitting\n",
    "\n",
    "Họ tên: Ngô Văn Hùng\n",
    "\n",
    "MSSV: 1412214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cách làm bài và nộp bài\n",
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài tự động nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân (ví dụ, bạn không được tự tiện xóa cell, ...).\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()```\n",
    "hoặc (đối với markdown cell):\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một cell chứa các bộ test để giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng :-).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>. Bạn có thể thảo luận ý tưởng với bạn khác, nhưng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font>. <font color=red>Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart & Run All` để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart & Run All` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, trong thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) bạn đặt các file: `BT04-TienXuLy_ChongOverfit.ipynb`, `train.csv`, `test.csv`; rồi nén thư mục `MSSV` này lại và nộp ở link trên moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tổng thể về nội dung bài tập\n",
    "\n",
    "Trong bài này, bạn sẽ thực hành: (i) tiền xử lý dữ liệu, và (ii) huấn luyện Neural Net với L2 regularization (weight decay) và early stopping. Bộ dữ liệu được sử dụng là bộ [Kaggle Titanic](https://www.kaggle.com/c/titanic); trong đó, input là thông tin của hành khách trên tàu Titanic, output là một trong hai lớp sống/chết (1/0). Mình có đính kèm các file dữ liệu mà Kaggle cung cấp: `train.csv` - tập huấn luyện, `test.csv` - tập kiểm tra (chỉ có input). Bạn xem ý nghĩa của các cột trong file `description.txt` đính kèm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import \n",
    "<font color=red>Lưu ý: bài tập này sẽ cần Sklearn phiên bản > 0.19</font>. Bạn xem phiên bản của Sklearn bằng câu lệnh ở dưới; nếu không thỏa thì bạn cần cập nhật Anaconda bằng cách: \n",
    "- Mở PowerShell (mình giả sử bạn dùng Windows)\n",
    "- Gõ 2 câu lệnh sau:\n",
    "    - `conda update conda`\n",
    "    - `conda update anaconda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer #version 0.2 trở lên\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from copy import deepcopy\n",
    "# You can also import other things ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Đọc tập huấn luyện vào data frame và tách ra tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
      "       'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "(891, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('train.csv', index_col=0)\n",
    "print(data_df.columns)\n",
    "print(data_df.shape)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Ticket      891 non-null object\n",
      "Fare        891 non-null float64\n",
      "Cabin       204 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andersson, Miss. Sigrid Elisabeth</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived      Pclass                               Name   Sex  \\\n",
       "count   891.000000  891.000000                                891   891   \n",
       "unique         NaN         NaN                                891     2   \n",
       "top            NaN         NaN  Andersson, Miss. Sigrid Elisabeth  male   \n",
       "freq           NaN         NaN                                  1   577   \n",
       "mean      0.383838    2.308642                                NaN   NaN   \n",
       "std       0.486592    0.836071                                NaN   NaN   \n",
       "min       0.000000    1.000000                                NaN   NaN   \n",
       "25%       0.000000    2.000000                                NaN   NaN   \n",
       "50%       0.000000    3.000000                                NaN   NaN   \n",
       "75%       1.000000    3.000000                                NaN   NaN   \n",
       "max       1.000000    3.000000                                NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch    Ticket        Fare        Cabin  \\\n",
       "count   714.000000  891.000000  891.000000       891  891.000000          204   \n",
       "unique         NaN         NaN         NaN       681         NaN          147   \n",
       "top            NaN         NaN         NaN  CA. 2343         NaN  C23 C25 C27   \n",
       "freq           NaN         NaN         NaN         7         NaN            4   \n",
       "mean     29.699118    0.523008    0.381594       NaN   32.204208          NaN   \n",
       "std      14.526497    1.102743    0.806057       NaN   49.693429          NaN   \n",
       "min       0.420000    0.000000    0.000000       NaN    0.000000          NaN   \n",
       "25%      20.125000    0.000000    0.000000       NaN    7.910400          NaN   \n",
       "50%      28.000000    0.000000    0.000000       NaN   14.454200          NaN   \n",
       "75%      38.000000    1.000000    0.000000       NaN   31.000000          NaN   \n",
       "max      80.000000    8.000000    6.000000       NaN  512.329200          NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = data_df[\"Survived\"]\n",
    "X_df = data_df.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>3</td>\n",
       "      <td>Larsson, Mr. Bengt Edvin</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347067</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasic, Mr. Jakob</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315097</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>3</td>\n",
       "      <td>Thorneycroft, Mr. Percival</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>376564</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2</td>\n",
       "      <td>Lehmann, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC 1748</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                        Name     Sex   Age  SibSp  Parch  \\\n",
       "PassengerId                                                                   \n",
       "232               3    Larsson, Mr. Bengt Edvin    male  29.0      0      0   \n",
       "837               3            Pasic, Mr. Jakob    male  21.0      0      0   \n",
       "640               3  Thorneycroft, Mr. Percival    male   NaN      1      0   \n",
       "390               2       Lehmann, Miss. Bertha  female  17.0      0      0   \n",
       "598               3         Johnson, Mr. Alfred    male  49.0      0      0   \n",
       "\n",
       "              Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                   \n",
       "232           347067   7.7750   NaN        S  \n",
       "837           315097   8.6625   NaN        S  \n",
       "640           376564  16.1000   NaN        S  \n",
       "390          SC 1748  12.0000   NaN        C  \n",
       "598             LINE   0.0000   NaN        S  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tách tập train và tập validation theo tỉ lệ 70%:30%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3, stratify=y_sr, random_state=0)\n",
    "train_y = train_y_sr.values\n",
    "val_y = val_y_sr.values\n",
    "\n",
    "train_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Mình đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của mình ra giống với của bạn. Tuy nhiên, mình không biết là với các hệ điều hành khác nhau thì điều này có được đảm bảo không. Kết quả của câu lệnh `train_X_df.head().index` của mình ra 5 giá trị là: `[232, 837, 640, 390, 598]`. Nếu của bạn ra khác thì bạn báo lại trên moodle, vì nếu ra khác thì các kết quả lúc sau của bạn cũng sẽ khác với của mình. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 623 entries, 232 to 81\n",
      "Data columns (total 10 columns):\n",
      "Pclass      623 non-null int64\n",
      "Name        623 non-null object\n",
      "Sex         623 non-null object\n",
      "Age         496 non-null float64\n",
      "SibSp       623 non-null int64\n",
      "Parch       623 non-null int64\n",
      "Ticket      623 non-null object\n",
      "Fare        623 non-null float64\n",
      "Cabin       143 non-null object\n",
      "Embarked    621 non-null object\n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 53.5+ KB\n"
     ]
    }
   ],
   "source": [
    "print(train_X_df.shape)\n",
    "train_X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 268 entries, 422 to 608\n",
      "Data columns (total 10 columns):\n",
      "Pclass      268 non-null int64\n",
      "Name        268 non-null object\n",
      "Sex         268 non-null object\n",
      "Age         218 non-null float64\n",
      "SibSp       268 non-null int64\n",
      "Parch       268 non-null int64\n",
      "Ticket      268 non-null object\n",
      "Fare        268 non-null float64\n",
      "Cabin       61 non-null object\n",
      "Embarked    268 non-null object\n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print(val_X_df.shape)\n",
    "val_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tiền xử lý tập huấn luyện (3.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, với cột `Name`, ta sẽ tiến hành rút trích ra cột `Title` tương ứng, gồm các giá trị như `Miss`, `Mrs`, `Mr`, `Master` ..., vì trong tên thì phần này có vẻ là sẽ có ích cho việc dự đoán sống/chết. Bạn hãy đếm số lần xuất hiện của mỗi giá trị trong cột `Title` và lưu kết quả vào biến `title_counts` (là Series với index là các giá trị có thể có của `Title`); bạn lưu ý: không làm thay đổi `train_X_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f544ac6be5b38cb2242b5533174c91b0",
     "grade": false,
     "grade_id": "cell-81f57381ec48178b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description category of people\n",
      " Mr          357\n",
      "Miss        125\n",
      "Mrs          89\n",
      "Master       32\n",
      "Dr            7\n",
      "Rev           5\n",
      "Countess      1\n",
      "Ms            1\n",
      "Jonkheer      1\n",
      "Capt          1\n",
      "Mme           1\n",
      "Col           1\n",
      "Mlle          1\n",
      "Don           1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "train_X_df_template = train_X_df.copy()\n",
    "train_X_df_template[\"Title\"] = train_X_df_template.loc[:, \"Name\"].apply(lambda x : 'NaN'.join(re.findall('([a-zA-z]+)\\.',x)))\n",
    "# train_X_df_template[\"Title\"] = train_X_df_template.loc[:, \"Name\"].str.extract(\"([a-zA-z]+)\\.\", expand=False)\n",
    "title_counts = train_X_df_template[\"Title\"].value_counts()\n",
    "print(\"Description category of people\\n\", title_counts)\n",
    "# title_counts: is Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6fa9b4cdbebc841298ec3c82d9d6d618",
     "grade": true,
     "grade_id": "cell-99110bf4db3c57f2",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert len(title_counts) == 14\n",
    "assert title_counts.loc[\"Mr\"] == 357\n",
    "assert title_counts.loc[\"Miss\"] == 125\n",
    "assert title_counts.loc[\"Mrs\"] == 89\n",
    "assert title_counts.loc[\"Master\"] == 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class `ColDropper` mà mình đã viết sẵn cho bạn dưới đây (theo dạng Transfomer của Sklearn) sẽ thực hiện các công việc:\n",
    "- Thêm cột `Title` vào DataFrame, trong đó ta sẽ chuyển các giá trị xuất hiện ít (không thuộc tập `[\"Mr\", \"Miss\", \"Mrs\", \"Master\"]`) thành giá trị `Rare`.\n",
    "- Bỏ cột `Name`.\n",
    "- Bỏ cột `Cabin` vì cột này có nhiều giá thiếu, và có vẻ cột này sẽ không giúp ích được gì nhiều cho việc dự đoán sống/chết.\n",
    "- Bỏ cột `Ticket` vì cột này có giá trị không phải dạng số, sẽ cần phải tốn sức để chuyển sang dạng số, và có vẻ cột này cũng sẽ không giúp ích được gì nhiều cho việc dự đoán sống/chết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "      <td>Master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked   Title\n",
       "PassengerId                                                              \n",
       "635               3  female   9.0      3      2  27.9000        S    Miss\n",
       "49                3    male   NaN      2      0  21.6792        C      Mr\n",
       "460               3    male   NaN      0      0   7.7500        Q      Mr\n",
       "111               1    male  47.0      0      0  52.0000        S      Mr\n",
       "126               3    male  12.0      1      0  11.2417        C  Master"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_title_col=True):\n",
    "        self.add_title_col = add_title_col\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        X_df = X_df.copy()\n",
    "        if self.add_title_col:\n",
    "            title_col = X_df.Name.str.extract(\"([a-zA-z]+)\\.\", expand=False)\n",
    "            non_rare_titles = [\"Mr\", \"Miss\", \"Mrs\", \"Master\"]\n",
    "            title_col[~title_col.isin(non_rare_titles)] = \"Rare\"\n",
    "            X_df[\"Title\"] = title_col\n",
    "        dropped_cols = ['Name', 'Ticket', 'Cabin']\n",
    "        X_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "        return X_df\n",
    "# Test ColDropper\n",
    "col_dropper = ColDropper()\n",
    "fewer_cols_train_X_df = col_dropper.fit_transform(train_X_df)\n",
    "fewer_cols_train_X_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đến đây, các cột dạng số gồm:`Pclass`, `Age`, `SibSp`, `Parch`, `Fare`; các cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical) gồm: `Sex`, `Embarked`, `Title`. Các bước tiền xử lý tiếp theo như sau:\n",
    "- Với các cột dạng số, ta sẽ điền giá trị thiếu bằng giá trị mean của cột <font color=blue>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng số trong tập huấn luyện, ta đều cần tính mean; vì ta không biết được cột nào sẽ bị thiếu giá trị khi test. \n",
    "- Với các cột dạng chuỗi có giá trị rời rạc không thứ tự:\n",
    "    - Ta sẽ điền giá trị thiếu bằng giá trị mode (giá trị xuất hiện nhiều nhất) của cột <font color=blue>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng chuỗi có giá trị rời rạc không thứ tự trong tập huấn luyện, ta đều cần tính mode; vì ta không biết được cột nào sẽ bị thiếu giá trị khi test.\n",
    "    - Sau đó, ta sẽ chuyển sang dạng số bằng phương pháp mã hóa one-hot <font color=blue>(gợi ý: dùng `OneHotEncoder` trong Sklearn)</font>.\n",
    "- Cuối cùng, khi tất cả các cột đã được điền giá trị thiếu và đã có dạng số, ta sẽ tiến hành chuẩn hóa bằng cách trừ đi mean và chia cho độ lệch chuẩn của cột để giúp cho các thuật toán cực tiểu hóa như Gradient Descent, LBFGS, ... hội tụ nhanh hơn <font color=blue>(gợi ý: dùng `StandardScaler` trong Sklearn)</font>.\n",
    "\n",
    "Nhiệm vụ của bạn là tạo ra một pipeline, đặt tên là `full_preprocess_pipeline`, bao gồm: bước thêm cột `Title` và bỏ các cột (đã nói ở lúc trước, đã cài cho bạn ở class `ColDropper`), và tất cả các bước ở đây. Sau khi tạo ra được pipeline này rồi, bạn sẽ gọi phương thức `fit_transform` với đầu vào là `train_X_df` để tính các tham số (ví dụ, mean và mode ở bước xử lý giá trị thiếu, mean và độ lệch chuẩn ở bước chuẩn hóa, ...) và đồng thời tiền xử lý `train_X_df`; kết quả trả về sẽ là `train_X_df` sau khi đã tiền xử lý, là một mảng Numpy, bạn đặt tên là `preprocessed_train_X`. <font color=blue>(Gợi ý: dùng `Pipeline` hoặc `make_pipeline`trong Sklearn, bạn có thể xem sự khác biệt của 2 cái này [ở đây](https://stackoverflow.com/questions/40708077/what-is-the-difference-between-pipeline-and-make-pipeline-in-scikit); ngoài ra, có thể dùng `ColumnTransformer` hoặc `make_column_transformer` để tạo ra một pipeline mà gồm vài pipeline thành phần, các pipeline thành phần làm trên các tập cột khác nhau trong DataFrame.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5adc8e3b16729375955fa1a5d9c20a71",
     "grade": false,
     "grade_id": "cell-ae75d7dfa7256c7f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_cols = ['Sex', 'Embarked', 'Title']\n",
    "# YOUR CODE HERE\n",
    "num_cols_pipeline = Pipeline([\n",
    "     ('simple_imputer_mean', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "\n",
    "cat_cols_pipeline = Pipeline([\n",
    "     ('simple_imputer_most', SimpleImputer(strategy='most_frequent')),\n",
    "     ('onehostEncoding', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "scaler_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_cols', num_cols_pipeline, num_cols),\n",
    "        ('cat_cols', cat_cols_pipeline, cat_cols)\n",
    "    ])\n",
    "\n",
    "full_preprocess_pipeline = Pipeline(steps=[\n",
    "                              ('preprocessor', preprocessor),\n",
    "                              ('scaler_final', StandardScaler())\n",
    "                           ])\n",
    "preprocessed_train_X = full_preprocess_pipeline.fit_transform(fewer_cols_train_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3d036c929508bb72d4bafc52db8b745d",
     "grade": true,
     "grade_id": "cell-1cf65ae2cdb14c0c",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert preprocessed_train_X.shape == (623, 15)\n",
    "row0 = {-0.736, -0.501, -0.481, -0.48, -0.479, -0.478, -0.408, -0.295, -0.233, -0.182, -0.041, 0.603, 0.736, 0.844, 0.863}\n",
    "row1 = {-0.736, -0.664, -0.501, -0.481, -0.48, -0.478, -0.463, -0.408, -0.295, -0.233, -0.182, 0.603, 0.736, 0.844, 0.863}\n",
    "assert set(np.round(preprocessed_train_X[0], decimals=3)) == row0\n",
    "assert set(np.round(preprocessed_train_X[1], decimals=3)) == row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý tập validation (1.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một khi đã có `full_preprocess_pipeline` với các tham số đã được tính từ tập huấn luyện, ta có thể dễ dàng dùng phương thức `transform` để tiền xử lý cho các input mới trong tập validation và tập test. Dưới đây, bạn sẽ làm như vậy để tiền xử lý cho `val_X_df` và lưu kết quả vào `preprocessed_val_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "986f547abfe534258eb2c41f692c1084",
     "grade": false,
     "grade_id": "cell-5b00ff693785976e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.844, -0.664, -0.481, -0.48 , -0.48 , -0.736,  0.736, -0.478,\n",
       "        3.385, -1.659, -0.233, -0.501,  0.863, -0.408, -0.182])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "col_dropper_val = ColDropper()\n",
    "fewer_cols_val_X_df = col_dropper_val.transform(val_X_df)\n",
    "preprocessed_val_X = full_preprocess_pipeline.transform(fewer_cols_val_X_df)\n",
    "\n",
    "np.round(preprocessed_val_X[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1cfaf89e2a1eb8b5b1080c889fa543e",
     "grade": true,
     "grade_id": "cell-b9c978682fecdf3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert preprocessed_val_X.shape == (268, 15)\n",
    "row0 = {-1.659, -0.736, -0.664, -0.501, -0.481, -0.48, -0.478, -0.408, -0.233, -0.182, 0.736, 0.844, 0.863, 3.385}\n",
    "row1 = {-1.988, -1.358, -1.158, -0.478, -0.408, -0.346, -0.295, -0.233, -0.182, 0.098, 0.603, 0.831, 1.358, 1.38, 1.996}\n",
    "assert set(np.round(preprocessed_val_X[0], 3)) == row0\n",
    "assert set(np.round(preprocessed_val_X[1], 3)) == row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích tại sao không nên làm 2 cách sau:\n",
    "- Tiền xử lý tập validation bằng các tham số của tập validation\n",
    "- Hoặc tiền xử lý tất cả dữ liệu rồi mới tách tập validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2a1567a9361126ee5dd2d6371498efda",
     "grade": true,
     "grade_id": "cell-c9f9e4ac63684628",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE \n",
    "\n",
    "- sử dụng bộ Validation thì mô hình có thể đã mất một phần dữ liệu của mình cho đào tạo mô hình. Trong trường hợp này, một nửa số liệu không đóng góp cho việc đào tạo mô hình! Điều này không tối ưu và có thể gây ra sự cố, đặc biệt nếu bộ dữ liệu đào tạo ban đầu nhỏ.(Cross-validation) \n",
    "- việc xử lý dữ liệu trước khi tách sẽ làm rò rỉ dữ liệu (leak information). Vì bạn có thể gặp trường hợp dữ liệu bên  tập test để tính toán (fit - training) chính điều nãy cũng gây nên sự không chính xác trong dự đoán dữ liệu thực tế (có thể dẫn tới overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Huấn luyện Neural Network với L2 regularization (2đ)\n",
    "Để thấy được ảnh hưởng của L2 regularization (weight decay) tới quá trình học, bạn sẽ huấn luyện 5 mô hình Neural Net với 5 giá trị `alpha` khác nhau: 0.1, 1, 10, 100, 1000; các siêu tham số khác cố định như sau: `hidden_layer_sizes=(50), activation=\"tanh\", solver=\"lbfgs\", random_state=0`. Mỗi mỗi mô hình, bạn in ra độ lỗi trên tập huấn luyện và trên tập validation. Cuối cùng, bạn chọn mô hình tốt nhất là mô hình có độ lỗi trên tập validation nhỏ nhất; bạn lưu mô hình này vào biến `best_l2_nnet` và lưu độ lỗi tương ứng trên tập validation vào biến `best_l2_val_err`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "893a3bcd668790a3aa75cd6e88b6393a",
     "grade": true,
     "grade_id": "cell-e066cce3255f3b17",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =    0.1, train_err =   6.74%, val_err =  20.90%\n",
      "alpha =    1.0, train_err =  11.56%, val_err =  17.91%\n",
      "alpha =   10.0, train_err =  17.50%, val_err =  16.79%\n",
      "alpha =  100.0, train_err =  19.10%, val_err =  19.40%\n",
      "alpha = 1000.0, train_err =  38.36%, val_err =  38.43%\n",
      "\n",
      "best_l2_val_err =  16.79%\n"
     ]
    }
   ],
   "source": [
    "best_l2_nnet = None\n",
    "best_l2_val_err = float(\"inf\")\n",
    "for alpha in [0.1, 1, 10 ,100, 1000]:\n",
    "    # YOUR CODE HERE\n",
    "    best_l2_nnet = MLPClassifier(hidden_layer_sizes=(50), activation=\"tanh\", \n",
    "                                 alpha=alpha, solver='lbfgs', \n",
    "                                 random_state=0)\n",
    "    best_l2_nnet.fit(preprocessed_train_X, train_y_sr)\n",
    "    train_score = best_l2_nnet.score(preprocessed_train_X, train_y_sr)\n",
    "    validation_score = best_l2_nnet.score(preprocessed_val_X, val_y_sr) \n",
    "    if (1 - validation_score) < best_l2_val_err:\n",
    "        best_l2_val_err = 1 - validation_score\n",
    "    print(\"alpha = {:6.1f}, train_err = {:6.2f}%, val_err = {:6.2f}%\".format(alpha, (1 - train_score) * 100, (1 - validation_score) * 100))\n",
    "    \n",
    "print(\"\\nbest_l2_val_err = {:6.2f}%\".format(best_l2_val_err * 100))\n",
    "\n",
    "# Kết quả của mình:\n",
    "# alpha =    0.1, train_err =   6.42%, val_err =  20.90%\n",
    "# alpha =    1.0, train_err =  11.56%, val_err =  17.91%\n",
    "# alpha =   10.0, train_err =  17.50%, val_err =  16.79%\n",
    "# alpha =  100.0, train_err =  19.10%, val_err =  19.40%\n",
    "# alpha = 1000.0, train_err =  38.36%, val_err =  38.43% \n",
    "# best_l2_val_err =  16.79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy nhận xét và giải thích kết quả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "72b167a2053875596214c026d78da492",
     "grade": true,
     "grade_id": "cell-2c31e8216f055991",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "- Nhận xét ta thấy rằng với alpha = 10.0 thì có vẻ như đạt cực tiểu local (local minize)\n",
    "ta thấy rằng các alpha đều đi qua điểm local minize thì alpha bằng 10 có vẻ như là khoảng tốt nhất vì error thấp. Nhưng như vậy là chưa đủ chỉ là chúng ta tìm thấy local minize trong các khoảng cho trước. Khẳng định chắc chắn khi ta thấy alpha = 1.0 ---> 10.0 thì có error chệnh lệch nhau không nhiều vậy từ đây ta suy ra là 1.0 --> 100.0 mang đò thị lõm ở đó. Em nghĩ chúng ta nên chọn learning rate trong khoảng này là ổn nhất "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Huấn luyện Neural Network với early stopping (2đ)\n",
    "\n",
    "Để thí nghiệm early stopping, ta sẽ huấn luyện Neural Net với 200 vòng lặp và chọn ra mô hình có độ lỗi nhỏ nhất trên tập validation; các siêu tham số khác cố định như sau: `alpha=0, hidden_layer_sizes=(50), activation=\"tanh\", solver=\"lbfgs\", random_state=0`. Bạn sẽ lưu mô hình tốt nhất vào biến `best_es_nnet` và độ lỗi tương ứng trên tập validation vào biến `best_es_val_err`. Bạn cũng cần lưu độ lỗi trên tập huấn luyện sau mỗi epoch vào biến `train_errs` (là một list, `len(train_errs)=200`); làm tương tự cho độ lỗi trên tập validation với biến `val_errs`.\n",
    "\n",
    "Trong Sklearn, để có thể can thiệp vào sau mỗi vòng lặp trong quá trình huấn luyện, bạn có thể tạo `MLPClassifier` với siêu tham số `max_iter=1` và `warm_start=True`. Sau đó, bạn có thể tự viết một vòng lặp, ở mỗi vòng lặp thì gọi phương thức `fit`; `warm_start=True` sẽ lấy các giá trị tham số ở trước đó làm điểm bắt đầu của phương thức `fit`, chứ không khởi tạo lại từ đầu nữa. Mình có thử so sánh cho `max_iter=200` và lặp 1 lần với cho `max_iter=1` và lặp 200 lần thì thấy cách đầu cho độ lỗi trên tập huấn luyện thấp hơn; nguyên nhân có thể là do thuật toán LBFGS bình thường có sử dụng các thông tin ở các bước đi trước để giúp ra quyết định tốt hơn về bước đi ở thời điểm hiện tại, nhưng mỗi khi gọi phương thức `fit` thì thuật toán LBFGS bị reset lại, các thông tin về các bước đi trước không còn nữa. Tuy nhiên, tạm thời ở đây sẽ bỏ qua vấn đề này.\n",
    "\n",
    "Ngoài ra, trong quá trình huấn luyện, để lưu lại mô hình với các giá trị tham số hiện tại, bạn có thể dùng hàm `deepcopy` mà mình đã import cho bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eb078b5c4b761a07e55081eaebe5d19b",
     "grade": true,
     "grade_id": "cell-d49f8a1a1e34df0a",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "nnet = MLPClassifier(hidden_layer_sizes=(50), activation=\"tanh\",\n",
    "                     solver=\"lbfgs\", alpha=0, random_state=0, \n",
    "                     max_iter=1, warm_start=True)\n",
    "max_iter = 200\n",
    "best_es_nnet = None\n",
    "best_es_val_err = float(\"inf\")\n",
    "val_errs = []\n",
    "train_errs = []\n",
    "\n",
    "for iteration in range(max_iter):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "print(\"best_es_val_err = {:5.2f}%\".format(best_es_val_err))\n",
    "# Kết quả của mình:\n",
    "# best_es_val_err = 15.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa quá trình huấn luyện với early stopping\n",
    "plt.plot(train_errs, \"b\", label=\"train_err\")\n",
    "plt.plot(val_errs, \"g\", label=\"val_err\")\n",
    "plt.legend()\n",
    "plt.xlim(0, len(train_errs)-1)\n",
    "min_y, max_y = plt.ylim()\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.xlabel(\"num epochs\")\n",
    "plt.ylabel(\"error (%)\")\n",
    "best_iter = np.argmin(val_errs)\n",
    "plt.plot([best_iter, best_iter], [min_y, max_y], \"r\")\n",
    "plt.text(best_iter + 1, max_y - 1, 'STOP', color=\"r\");\n",
    "# Bạn có thể xem kết quả của mình trong file \"early_stopping.png\" đính kèm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy nhận xét và giải thích về đồ thị kết quả ở trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f2377b9fe6bf1644a4fa5e1dbeaea1de",
     "grade": true,
     "grade_id": "cell-59e097d71d937ed3",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Kiểm tra (1đ)\n",
    "\n",
    "Trong hai mô hình `best_l2_nnet` và `best_es_nnet`, bạn sẽ chọn mô hình có độ lỗi nhỏ nhất trên tập validation là mô hình cuối cùng (của mình là mô hình `best_es_nnet`). Sau đó, bạn sẽ dùng `full_preprocess_pipeline` + mô hình này để dự đoán với các input trong tập test (file \"test.csv\") và submit kết quả dự đoán lên Kaggle. Để có thể submit thì bạn phải tạo ra file csv có 2 cột: cột thứ nhất là id của các hành khách trong tập test, cột thứ hai là giá trị dự đoán của bạn (1 - sống, và 0 - chết). Bạn có thể xem file mẫu `submission.csv` mà mình đính kèm. Bạn đặt tên file của bạn là `my_preds.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dea94865c1b1cddb8fbfb49cf3907c63",
     "grade": true,
     "grade_id": "cell-e184d7a3003ba334",
     "locked": false,
     "points": 0.75,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Kế đến, bạn sẽ submit file csv chứa kết quả dự đoán lên [Kaggle](https://www.kaggle.com/c/titanic) (bạn sẽ cần tạo một account trên Kaggle), và ghi nhận lại độ lỗi trên tập test ở cell phía dưới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b369b7d7c79e9110cb16f28db1c29ef0",
     "grade": true,
     "grade_id": "cell-0a8a2d0f116f035d",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
